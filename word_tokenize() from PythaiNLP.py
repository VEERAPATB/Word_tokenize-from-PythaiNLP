# -*- coding: utf-8 -*-
"""1630902094_Veerapat.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19Rc8WesCEsmqTMlp8FeNLhEIYgxss2mL

## Maximal Matching from PythaiNLP

### Default dictionary

Study word_tokenize() from PythaiNLP in the link below.

https://pythainlp.github.io/docs/3.1/api/tokenize.html#pythainlp.tokenize.word_tokenize
"""

!pip install pythainlp
!pip install marisa_trie
!pip install attacut
!pip install deepcut

import pythainlp
pythainlp.__version__

"""### **Formal Thai text**



> Ref:https://th.wikipedia.org/wiki/%E0%B8%8B%E0%B8%B9%E0%B9%80%E0%B8%9B%E0%B8%AD%E0%B8%A3%E0%B9%8C%E0%B8%84%E0%B8%AD%E0%B8%A1%E0%B8%9E%E0%B8%B4%E0%B8%A7%E0%B9%80%E0%B8%95%E0%B8%AD%E0%B8%A3%E0%B9%8C




"""

from pythainlp import word_tokenize
text= """ซูเปอร์คอมพิวเตอร์เป็นเครื่องคอมพิวเตอร์ที่เหมาะกับงานคำนวณที่ต้องมีการคำนวณตัวเลขจำนวนหลายล้านตัวภายในเวลาอันรวดเร็ว เช่น งานพยากรณ์อากาศ
ที่ต้องนำข้อมูลต่าง ๆ เกี่ยวกับอากาศทั้งระดับภาคพื้นดิน เเละระดับชึ้นบรรยากาศเพื่อดูการเคลื่อนไหวและการเปลี่ยนแปลงของอากาศงานนี้จำเป็นต้องใช้เครื่องคอมพิวเตอร์ที่มีสมรรถนะสูงมาก
นอกจากนี้มีงานอีกเป็นจำนวนมากที่ต้องใช้ซูปเปอร์คอมพิวเตอร์ซึ่งมีความเร็วสูง เช่น งานการวิจัยนิวเคลียร์
งานควบคุมทางอวกาศ
"""

token_01 = word_tokenize(text,engine='newmm')
token_02 = word_tokenize(text,engine='attacut')
token_03 = word_tokenize(text,engine='deepcut')

print("Default Text: ", text)
print("\nEngine(newmm) [",len(token_01),"] = " , token_01)
print("\nEngine(attacut) [",len(token_02),"] = " , token_02)
print("\nEngine(deepcut) [",len(token_03),"] = " , token_03)

"""### Custom dictionary

"""

from pythainlp.corpus.common import thai_words
from pythainlp.util import Trie

print("Default dictionary: ",token_01)
new_words = {"ตัวเลข","เครื่อง","ซูปเปอร์คอมพิวเตอร์","ต้องมี","ซูเปอร์คอมพิวเตอร์","นำข้อมูล","สูงมาก","เเละ"}
words = new_words.union(thai_words())

custom_dictionary_trie = Trie(words)

tokens = word_tokenize(text, custom_dict=custom_dictionary_trie, engine='newmm')
print("\nEngine(newmm) [",len(tokens),"] = " , tokens)

"""### **Analyze**

> โดยภาพรวมเเล้ว Engine(attacut, deepcut) มีความเเม่นยำกว่าตัวของ Engine(newmm, newmm dictionary) เเต่จะใช้เวลาในการคำนวณที่มากกว่าถ้าสรุปภาพรวมขึ้นอยู่กับทาง dev ว่าเลือกที่จะใช้เวลาเเต่เเม่นยำ หรือเร็วเเต่ลดความเเม่นยำลง เเต่ถ้าสรุปใน Data นี้คิดว่า deepcut มี performance สูงที่สุด เพราะมีความเเม่นยำสูงเเละมีเวลาคำนวณที่น้อยลงมากำลังดี




> ด้านล่างจะสรุปจำนวนคำที่ตัดได้จะเรียงจากน้อยไปมาก

*  newmm dictionary -> newmm -> deepcut -> attacut

### **Infomal Thai Text**
ref: https://filmclubthailand.com/review/film-review/avatar-thewayofwater/
"""

from pythainlp import word_tokenize
text= """Avatar: The Way of Water เป็นหนังภาคต่อ เรื่องราวเท้าความจากภาคเดิมที่ เจค ซัลลี นายทหารพิการคนหนึ่ง ได้เข้าร่วม
ปฏิบัติการกวาดล้างชาวนาวีบนดาวแพนดอรา ดาวที่มนุษย์โลกตั้งใจสร้างเป็นอาณานิคมหลังโลกล่มสลาย แต่แล้วเขากลับรับรู้ถึงคุณค่าอันลึกซึ้ง
ของชีวิตที่อยู่บนนั้นและกลายเป็นส่วนหนึ่งของชาวเผ่านาวีโดยสมบูรณ์แบบผ่านร่างอวตารที่สร้างขึ้นเพื่อเขา เจคได้กลายเป็นผู้นำของชาวเผ่านาวี เป็นวีรบุรุษสงครามที่ชาวเผ่าเรียกขานกันว่า
โทรุคมัคโต เขาได้แต่งงานกับเนทีรี ลูกสาวของหัวหน้าเผ่าคนก่อน และมีลูกด้วยกัน 4 คน
"""

token_01 = word_tokenize(text,engine='newmm')
token_02 = word_tokenize(text,engine='attacut')
token_03 = word_tokenize(text,engine='deepcut')

print("Default Text:", text)
print("\nEngine(newmm) [",len(token_01),"] = " , token_01)
print("\nEngine(attacut) [",len(token_02),"] = " , token_02)
print("\nEngine(deepcut) [",len(token_03),"] = " , token_03)

"""### **Custom dictionary**"""

from pythainlp.corpus.common import thai_words
from pythainlp.util import Trie

print("Default dictionary: ",token_01)
new_words = {"ภาคต่อ","เจค ซัลลี","คนหนึ่ง","ชาวนาวี","ดาวแพนดอรา","ชาวเผ่านาวี","สูงมาก","เเละ"}
words = new_words.union(thai_words())

custom_dictionary_trie = Trie(words)

tokens = word_tokenize(text, custom_dict=custom_dictionary_trie, engine='newmm')
print("\nEngine(newmm) [",len(tokens),"] = " , tokens)

"""### **Analyze**

> โดยภาพรวมเเล้ว Engine(attacut, deepcut) ก็ยังมีความเเม่นยำกว่าตัวของ Engine(newmm, newmm dictionary) เเต่จะใช้เวลาในการคำนวณที่มากกว่า โดย text ชุดนี้ส่วนใหญ่เป็นคำที่ตัดเเล้วยังพออ่านเข้าใจได้ต่างจาก Formal thai text ที่มีคำศัพท์ที่ยาก เลยคิดว่า Engine(newmm directional) มี performance ที่สูงสุดจาก Engine อื่นๆ เพราะไม่จำเป็นต้องมีความเเม่นยำขนาดนั้น เเต่ต้อง add-on คำเพิ่มเติมเล็กน้อย(จำพวกชื่อตัวละคร หรือคำใหม่)

> ด้านล่างจะสรุปจำนวนคำที่ตัดได้จะเรียงจากน้อยไปมาก

*   newmm dictionary -> deepcut -> attacut -> newmm






"""